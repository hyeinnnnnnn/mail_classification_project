"""
from kiwipiepy import Kiwi
from sentence_transformers import SentenceTransformer, util
import pymysql
import re

# ëª¨ë¸ ë° í˜•íƒœì†Œ ë¶„ì„ê¸° ì´ˆê¸°í™”
model = SentenceTransformer("snunlp/KR-SBERT-V40K-klueNLI-augSTS")
kiwi = Kiwi()

# DB ì—°ê²°
conn = pymysql.connect(
    host='10.50.131.18',
    port=3306,
    user='user',
    password='user1234',
    database='maildb',
    charset='utf8'
)
cursor = conn.cursor()

# í‚¤ì›Œë“œ í…Œì´ë¸” ëª©ë¡
keyword_tables = ['finance_keywords', 'government_keywords', 'portal_keywords', 'advertisement_keywords']

# ëª…ì‚¬/í˜•ìš©ì‚¬ë§Œ ì¶”ì¶œ
def extract_keywords(text):
    tokens = kiwi.tokenize(text)
    return [token.form for token in tokens if token.tag in ("NNG", "NNP", "VA") and token.form.isalpha()]

def get_keywords_from_table(table_name):
    cursor.execute(f"SELECT keywordnum, word, similarity FROM {table_name}")
    return cursor.fetchall()

def keyword_exists(table_name, word):
    cursor.execute(f"SELECT 1 FROM {table_name} WHERE word = %s", (word,))
    return cursor.fetchone() is not None

def count_table_entries(table_name):
    cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
    return cursor.fetchone()[0]

def delete_lowest_similarity_keyword(table_name):
    cursor.execute(f"SELECT keywordnum FROM {table_name} ORDER BY similarity ASC LIMIT 1")
    result = cursor.fetchone()
    if result:
        cursor.execute(f"DELETE FROM {table_name} WHERE keywordnum = %s", (result[0],))
        conn.commit()

def insert_keyword(table_name, word, similarity):
    cursor.execute(
        f"INSERT INTO {table_name}(word, similarity) VALUES (%s, %s)",
        (word, similarity)
    )
    conn.commit()

# ë©”ì¼ ì œëª© ì „ë¶€ ê°€ì ¸ì˜¤ê¸°
cursor.execute("SELECT title FROM mail_info")
titles = [row[0] for row in cursor.fetchall()]

# ì „ì²´ ì²˜ë¦¬
for title in titles:
    print(f"\nğŸ“¨ Processing title: {title}")
    tokens = extract_keywords(title)
    if not tokens:
        print("â›” No valid tokens found.")
        continue

    token_embeddings = model.encode(tokens, convert_to_tensor=True)

    for table in keyword_tables:
        keyword_rows = get_keywords_from_table(table)
        if not keyword_rows:
            print(f"âš ï¸  Table {table} is empty. Skipping.")
            continue

        max_similarity = 0.0
        best_token = None

        for i, token in enumerate(tokens):
            token_embedding = token_embeddings[i]
            for _, word, _ in keyword_rows:
                word_embedding = model.encode(word, convert_to_tensor=True)
                similarity = float(util.pytorch_cos_sim(token_embedding, word_embedding))
                if similarity > max_similarity:
                    max_similarity = similarity
                    best_token = token

        if best_token:
            if max_similarity <= 0.5:
                print(f"ğŸ§Š Token '{best_token}' skipped for {table} (similarity {max_similarity:.2f} too low).")
            elif keyword_exists(table, best_token):
                print(f"ğŸ” Token '{best_token}' already exists in {table}. Skipping.")
            else:
                if count_table_entries(table) >= 300:
                    delete_lowest_similarity_keyword(table)
                    print(f"ğŸ—‘ Deleted lowest similarity keyword from {table} to make room.")
                insert_keyword(table, best_token, max_similarity)
                print(f"âœ… Inserted '{best_token}' into {table} (similarity: {max_similarity:.2f})")

# ì—°ê²° ì¢…ë£Œ
cursor.close()
conn.close()
"""


#ë©”ì¼ íƒ€ì´í‹€ì—ì„œ í† í°ì„ ì¶”ì¶œí•˜ì—¬ í‚¤ì›Œë“œì™€ ìœ ì‚¬ë„ ê³„ì‚°í•˜ëŠ” ë°©ì‹
'''
from kiwipiepy import Kiwi
from sentence_transformers import SentenceTransformer, util
import pymysql
import re
import torch  # torch.meanì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì„í¬íŠ¸

# ëª¨ë¸ ë° í˜•íƒœì†Œ ë¶„ì„ê¸° ì´ˆê¸°í™”
model = SentenceTransformer("snunlp/KR-SBERT-V40K-klueNLI-augSTS")
kiwi = Kiwi()

# DB ì—°ê²°
conn = pymysql.connect(
    host='10.50.131.18',
    port=3306,
    user='user',
    password='user1234',
    database='maildb',
    charset='utf8'
)
cursor = conn.cursor()

# í‚¤ì›Œë“œ í…Œì´ë¸” ëª©ë¡
keyword_tables = ['finance_keywords', 'government_keywords', 'portal_keywords', 'advertisement_keywords']


# ëª…ì‚¬/í˜•ìš©ì‚¬ë§Œ ì¶”ì¶œ
def extract_keywords(text):
    tokens = kiwi.tokenize(text)
    # isalpha()ë¥¼ ì¶”ê°€í•˜ì—¬ ìˆ«ìë‚˜ íŠ¹ìˆ˜ë¬¸ìê°€ í¬í•¨ëœ í† í°ì€ ì œì™¸
    return [token.form for token in tokens if token.tag in ("NNG", "NNP") and token.form.isalpha()]


def get_keywords_from_table(table_name):
    cursor.execute(f"SELECT keywordnum, word, similarity FROM {table_name}")
    return cursor.fetchall()


# í‚¤ì›Œë“œê°€ ì¡´ì¬í•˜ë©´ í•´ë‹¹ í‚¤ì›Œë“œì˜ í˜„ì¬ ìœ ì‚¬ë„ë¥¼ ë°˜í™˜í•˜ê³ , ì—†ìœ¼ë©´ Noneì„ ë°˜í™˜
# ì´ì œ ì´ í•¨ìˆ˜ëŠ” í‚¤ì›Œë“œì˜ ì¡´ì¬ ì—¬ë¶€ë§Œ í™•ì¸í•˜ê³ , ì‹¤ì œ ìœ ì‚¬ë„ ê°’ì€ ì‚¬ìš©í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
# í•˜ì§€ë§Œ ì¼ê´€ì„±ì„ ìœ„í•´ ìœ ì§€í•˜ê±°ë‚˜, í•„ìš”ì— ë”°ë¼ wordë§Œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ë¡œ ë³€ê²½ ê°€ëŠ¥í•©ë‹ˆë‹¤.
def get_existing_keyword_similarity(table_name, word):
    cursor.execute(f"SELECT similarity FROM {table_name} WHERE word = %s", (word,))
    result = cursor.fetchone()
    return result[0] if result else None


def keyword_exists(table_name, word):
    cursor.execute(f"SELECT 1 FROM {table_name} WHERE word = %s", (word,))
    return cursor.fetchone() is not None


def count_table_entries(table_name):
    cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
    return cursor.fetchone()[0]


def delete_lowest_similarity_keyword(table_name):
    cursor.execute(f"SELECT keywordnum FROM {table_name} ORDER BY similarity ASC LIMIT 1")
    result = cursor.fetchone()
    if result:
        cursor.execute(f"DELETE FROM {table_name} WHERE keywordnum = %s", (result[0],))
        conn.commit()


def insert_keyword(table_name, word, similarity):
    cursor.execute(
        f"INSERT INTO {table_name}(word, similarity) VALUES (%s, %s)",
        (word, similarity)
    )
    conn.commit()


def update_keyword_similarity(table_name, word, new_similarity):
    cursor.execute(
        f"UPDATE {table_name} SET similarity = %s WHERE word = %s",
        (new_similarity, word)
    )
    conn.commit()


def keyword_exists_in_any_other_table(current_table_name, word):
    for table_name in keyword_tables:
        if table_name == current_table_name: # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ í…Œì´ë¸”ì€ ê±´ë„ˆê¹€
            continue
        cursor.execute(f"SELECT 1 FROM {table_name} WHERE word = %s", (word,))
        if cursor.fetchone() is not None:
            return True # ë‹¤ë¥¸ í…Œì´ë¸”ì—ì„œ ë°œê²¬ë¨
    return False # ë‹¤ë¥¸ í…Œì´ë¸”ì—ì„œëŠ” ë°œê²¬ë˜ì§€ ì•ŠìŒ

# ë©”ì¼ ì œëª© ì „ë¶€ ê°€ì ¸ì˜¤ê¸°
cursor.execute("SELECT detail FROM mail_info")
titles = [row[0] for row in cursor.fetchall()]

# ì „ì²´ ì²˜ë¦¬
for title in titles:
    print(f"\nğŸ“¨ Processing title: {title}")
    tokens = extract_keywords(title)
    if not tokens:
        print("â›” No valid tokens found.")
        continue

    # ë©”ì¼ ì œëª©ì˜ ëª¨ë“  í† í° ì„ë² ë”©
    title_token_embeddings = model.encode(tokens, convert_to_tensor=True)

    best_table_for_title = None
    max_avg_similarity_for_title = -1.0  # ë©”ì¼ ì œëª©ê³¼ í…Œì´ë¸” ê°„ì˜ ìµœê³  í‰ê·  ìœ ì‚¬ë„
    best_token_for_table_insertion = None  # ì‹¤ì œë¡œ ì‚½ì…/ì—…ë°ì´íŠ¸ë  í‚¤ì›Œë“œ

    # ê° í‚¤ì›Œë“œ í…Œì´ë¸”ë³„ í‰ê·  ìœ ì‚¬ë„ ê³„ì‚°
    for table_name in keyword_tables:
        keyword_rows = get_keywords_from_table(table_name)
        if not keyword_rows:
            print(f"âš ï¸  Table {table_name} is empty. Skipping average similarity calculation for this table.")
            continue

        table_words = [row[1] for row in keyword_rows]
        table_word_embeddings = model.encode(table_words, convert_to_tensor=True)

        # ë©”ì¼ ì œëª©ì˜ ëª¨ë“  í† í°ê³¼ í•´ë‹¹ í…Œì´ë¸”ì˜ ëª¨ë“  í‚¤ì›Œë“œ ê°„ì˜ ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚°
        # shape: (len(title_tokens), len(table_keywords))
        similarity_matrix = util.pytorch_cos_sim(title_token_embeddings, table_word_embeddings)

        # ê° ë©”ì¼ ì œëª© í† í°ë³„ë¡œ í…Œì´ë¸” ë‚´ í‚¤ì›Œë“œë“¤ê³¼ì˜ ìµœëŒ€ ìœ ì‚¬ë„ë¥¼ ì°¾ìŒ (ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ í‚¤ì›Œë“œë§Œ ê³ ë ¤)
        # shape: (len(title_tokens),)
        max_similarities_per_title_token = similarity_matrix.max(dim=1)[0]

        # í•´ë‹¹ í…Œì´ë¸”ì˜ ëª¨ë“  í‚¤ì›Œë“œë¥¼ ê³ ë ¤í•œ ë©”ì¼ ì œëª©ì˜ í‰ê·  ìœ ì‚¬ë„
        if len(max_similarities_per_title_token) > 0:
            avg_similarity_for_table = torch.mean(max_similarities_per_title_token).item()
        else:
            avg_similarity_for_table = 0.0  # ìœ ì‚¬ë„ ê³„ì‚°í•  í† í°ì´ ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ê°„ì£¼

        print(f"ğŸ“Š Average similarity for '{table_name}': {avg_similarity_for_table:.2f}")

        # í˜„ì¬ í…Œì´ë¸”ì´ ì§€ê¸ˆê¹Œì§€ ì°¾ì€ ìµœê³  í‰ê·  ìœ ì‚¬ë„ë¥¼ ê°€ì§„ í…Œì´ë¸”ì´ë¼ë©´ ì—…ë°ì´íŠ¸
        if avg_similarity_for_table > max_avg_similarity_for_title:
            max_avg_similarity_for_title = avg_similarity_for_table
            best_table_for_title = table_name

            # ì´ í…Œì´ë¸”ì— ì‚½ì…ë  ê°€ì¥ ì í•©í•œ ë‹¨ì¼ í‚¤ì›Œë“œë¥¼ ì°¾ìŠµë‹ˆë‹¤.
            # ì´ëŠ” ë©”ì¼ ì œëª©ì˜ í† í° ì¤‘, í•´ë‹¹ í…Œì´ë¸”ì˜ í‚¤ì›Œë“œë“¤ê³¼ ê°€ì¥ ë†’ì€ ìœ ì‚¬ë„ë¥¼ ë³´ì´ëŠ” í† í°ì…ë‹ˆë‹¤.
            if len(max_similarities_per_title_token) > 0:
                idx_of_best_token_in_title = torch.argmax(max_similarities_per_title_token).item()
                best_token_for_table_insertion = tokens[idx_of_best_token_in_title]
            else:
                best_token_for_table_insertion = None

    # ë©”ì¼ ì œëª© ì²˜ë¦¬ ì™„ë£Œ í›„, ê°€ì¥ ë†’ì€ í‰ê·  ìœ ì‚¬ë„ë¥¼ ë³´ì¸ í…Œì´ë¸”ì— ë‹¨ì¼ í‚¤ì›Œë“œ ë°˜ì˜
    # ë˜í•œ, ìµœì†Œí•œì˜ í‰ê·  ìœ ì‚¬ë„ ì„ê³„ì¹˜ë¥¼ ë„˜ì–´ì•¼ë§Œ ë°˜ì˜í•˜ë„ë¡ í•©ë‹ˆë‹¤.
    MIN_AVG_SIMILARITY_THRESHOLD = 0.35  # ì´ ê°’ì„ ì¡°ì ˆí•˜ì—¬ ë¯¼ê°ë„ë¥¼ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

    # ì „ì²´ ì²˜ë¦¬
    for title in titles:
        # ... (ê¸°ì¡´ ë©”ì¼ ì œëª© ì²˜ë¦¬ ë¡œì§ ìƒëµ) ...

        if best_table_for_title and best_token_for_table_insertion and max_avg_similarity_for_title >= MIN_AVG_SIMILARITY_THRESHOLD:
            target_table = best_table_for_title
            best_token = best_token_for_table_insertion
            similarity_to_save = max_avg_similarity_for_title

            print(f"ğŸ¯ Selected table: {target_table} (Avg Sim: {max_avg_similarity_for_title:.2f})")
            print(f"âœ¨ Candidate keyword for insertion/update: '{best_token}'")

            # 1. ë¨¼ì €, í˜„ì¬ ì„ íƒëœ í…Œì´ë¸”ì— í‚¤ì›Œë“œê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            if keyword_exists(target_table, best_token):
                existing_similarity = get_existing_keyword_similarity(target_table, best_token)

                if similarity_to_save > existing_similarity:  # ìƒˆ í‰ê·  ìœ ì‚¬ë„ê°€ ê¸°ì¡´ ìœ ì‚¬ë„ë³´ë‹¤ ë†’ë‹¤ë©´ ì—…ë°ì´íŠ¸
                    # 2. ë‹¤ë¥¸ í…Œì´ë¸”ì— ë™ì¼í•œ í‚¤ì›Œë“œê°€ ì—†ëŠ”ì§€ í™•ì¸ í›„ ì—…ë°ì´íŠ¸
                    if not keyword_exists_in_any_other_table(target_table, best_token):
                        update_keyword_similarity(target_table, best_token, similarity_to_save)
                        print(
                            f"ğŸ”„ Updated '{best_token}' in {target_table} with new average similarity: {similarity_to_save:.2f} (was: {existing_similarity:.2f})")
                    else:
                        print(
                            f"â›” Skipped update for '{best_token}' in {target_table}. It already exists in another table.")
                else:
                    print(
                        f"ğŸ” Token '{best_token}' already exists in {target_table} with higher or equal average similarity ({existing_similarity:.2f}). Skipping update.")
            else:  # í‚¤ì›Œë“œê°€ í˜„ì¬ í…Œì´ë¸”ì— ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´ ìƒˆë¡œ ì‚½ì…
                # 2. ë‹¤ë¥¸ í…Œì´ë¸”ì— ë™ì¼í•œ í‚¤ì›Œë“œê°€ ì—†ëŠ”ì§€ í™•ì¸ í›„ ì‚½ì…
                if not keyword_exists_in_any_other_table(target_table, best_token):
                    if count_table_entries(target_table) >= 300:
                        delete_lowest_similarity_keyword(target_table)
                        print(f"ğŸ—‘ Deleted lowest similarity keyword from {target_table} to make room.")
                    insert_keyword(target_table, best_token, similarity_to_save)
                    print(
                        f"âœ… Inserted '{best_token}' into {target_table} (average similarity: {similarity_to_save:.2f})")
                else:
                    print(
                        f"â›” Skipped insertion for '{best_token}' in {target_table}. It already exists in another table.")
        else:
            print(
                f"ğŸ¤· No sufficiently relevant table found for this title (Max Avg Sim: {max_avg_similarity_for_title:.2f}, Threshold: {MIN_AVG_SIMILARITY_THRESHOLD}).")
# ì—°ê²° ì¢…ë£Œ
cursor.close()
conn.close()
'''

import sys
from kiwipiepy import Kiwi
from sentence_transformers import SentenceTransformer, util
import pymysql
import re
import torch

# ëª¨ë¸ ë° í˜•íƒœì†Œ ë¶„ì„ê¸° ì´ˆê¸°í™”
model = SentenceTransformer("snunlp/KR-SBERT-V40K-klueNLI-augSTS")
kiwi = Kiwi()

# DB ì—°ê²°
try:
    conn = pymysql.connect(
        host='10.50.131.18',
        port=3306,
        user='user',
        password='user1234',
        database='maildb',
        charset='utf8'
    )
    cursor = conn.cursor()

except pymysql.Error as e:
    print(f"DB ì—°ê²° ì˜¤ë¥˜: {e}")
    sys.exit(1)

# í‚¤ì›Œë“œ í…Œì´ë¸” ëª©ë¡ (ì¹´í…Œê³ ë¦¬ ëª©ë¡)
keyword_tables = ['finance_keywords', 'government_keywords', 'portal_keywords', 'advertisement_keywords']


# ëª…ì‚¬/í˜•ìš©ì‚¬ë§Œ ì¶”ì¶œ (NNG: ì¼ë°˜ ëª…ì‚¬, NNP: ê³ ìœ  ëª…ì‚¬, VA: í˜•ìš©ì‚¬)
def extract_nouns_and_adjectives(text):
    tokens = kiwi.tokenize(text)
    return [token.form for token in tokens if token.tag in ("NNG", "NNP", "VA") and token.form.isalpha()]


def get_keywords_from_table(table_name):
    cursor.execute(f"SELECT word FROM {table_name}")
    return [row[0] for row in cursor.fetchall()]


def get_keyword_and_similarity_from_table(table_name, word):
    cursor.execute(f"SELECT similarity FROM {table_name} WHERE word = %s", (word,))
    result = cursor.fetchone()
    return result[0] if result else None


def count_table_entries(table_name):
    cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
    return cursor.fetchone()[0]


def delete_lowest_similarity_keyword(table_name):
    cursor.execute(f"SELECT keywordnum FROM {table_name} ORDER BY similarity ASC LIMIT 1")
    result = cursor.fetchone()
    if result:
        cursor.execute(f"DELETE FROM {table_name} WHERE keywordnum = %s", (result[0],))
        conn.commit()
        print(f"ğŸ—‘ Deleted lowest similarity keyword from {table_name} to make room.")
        return True
    return False


def insert_keyword(table_name, word, similarity):
    try:
        cursor.execute(
            f"INSERT INTO {table_name}(word, similarity) VALUES (%s, %s)",
            (word, similarity)
        )
        conn.commit()
        print(f"âœ… Inserted '{word}' into {table_name} (similarity: {similarity:.4f})")
        return True
    except pymysql.Error as e:
        print(f"DB ì‚½ì… ì˜¤ë¥˜ ({table_name}, {word}): {e}")
        conn.rollback()
        return False


def update_keyword_similarity(table_name, word, new_similarity):
    try:
        cursor.execute(
            f"UPDATE {table_name} SET similarity = %s WHERE word = %s",
            (new_similarity, word)
        )
        conn.commit()
        print(f"ğŸ”„ Updated '{word}' in {table_name} with new similarity: {new_similarity:.4f}")
        return True
    except pymysql.Error as e:
        print(f"DB ì—…ë°ì´íŠ¸ ì˜¤ë¥˜ ({table_name}, {word}): {e}")
        conn.rollback()
        return False


# ìˆ˜ì •ëœ í•¨ìˆ˜: í˜„ì¬ í…Œì´ë¸”ì„ ì œì™¸í•œ ë‹¤ë¥¸ í…Œì´ë¸”ì—ì„œ í‚¤ì›Œë“œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
def keyword_exists_in_any_other_table(current_table_name, word):
    """
    í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ í…Œì´ë¸”ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ í‚¤ì›Œë“œ í…Œì´ë¸”ì—ì„œ íŠ¹ì • í‚¤ì›Œë“œì˜ ì¡´ì¬ ì—¬ë¶€ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
    """
    for table_name in keyword_tables:
        if table_name == current_table_name:  # í˜„ì¬ í…Œì´ë¸”ì€ ê±´ë„ˆëœ€
            continue
        cursor.execute(f"SELECT 1 FROM {table_name} WHERE word = %s", (word,))
        if cursor.fetchone() is not None:
            return True  # ë‹¤ë¥¸ í…Œì´ë¸”ì—ì„œ ë°œê²¬ë¨
    return False  # ë‹¤ë¥¸ í…Œì´ë¸”ì—ì„œëŠ” ë°œê²¬ë˜ì§€ ì•ŠìŒ


if __name__ == "__main__":
    try:
        cursor.execute("SELECT detail FROM mail_info")
        titles_to_process = [row[0] for row in cursor.fetchall()]
    except pymysql.Error as e:
        print(f"ë©”ì¼ ì œëª© ì¡°íšŒ ì˜¤ë¥˜: {e}")
        conn.close()
        sys.exit(1)

    if not titles_to_process:
        print("ì²˜ë¦¬í•  ë©”ì¼ ì œëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
        conn.close()
        sys.exit(0)

    MAX_KEYWORDS_PER_TABLE = 300
    MIN_SIMILARITY_FOR_KEYWORD_ADDITION = 0.5

    for mail_idx, title in enumerate(titles_to_process):
        print(f"\n--- {mail_idx + 1}/{len(titles_to_process)} Processing Mail Title for Keyword Learning ---")
        display_title = title if len(title) < 70 else title[:67] + "..."
        print(f"  Mail Title: '{display_title}'")

        candidate_tokens = extract_nouns_and_adjectives(title)
        print(f"  DEBUG: Extracted candidate tokens: {candidate_tokens}")
        if not candidate_tokens:
            print(
                "â›” No valid noun/adjective tokens found in this mail title. Skipping keyword learning for this title.")
            continue

        candidate_token_embeddings = model.encode(candidate_tokens, convert_to_tensor=True)

        current_all_table_keywords = {}
        current_all_keyword_embeddings = {}

        for table_name in keyword_tables:
            keywords_in_table = get_keywords_from_table(table_name)
            current_all_table_keywords[table_name] = keywords_in_table
            if keywords_in_table:
                current_all_keyword_embeddings[table_name] = model.encode(keywords_in_table, convert_to_tensor=True)
            else:
                current_all_keyword_embeddings[table_name] = torch.tensor([])

        best_category_for_title_semantic = None
        highest_avg_sim_for_category = -1.0

        for table_name in keyword_tables:
            embeddings_in_table = current_all_keyword_embeddings[table_name]

            if not embeddings_in_table.numel():
                print(f"  âš ï¸  Category '{table_name}' has no embeddings. Skipping similarity calculation.")
                continue

            similarity_matrix = util.pytorch_cos_sim(candidate_token_embeddings, embeddings_in_table)
            max_sim_per_candidate_token_to_category = similarity_matrix.max(dim=1)[0]

            if len(max_sim_per_candidate_token_to_category) > 0:
                avg_sim_for_current_category = torch.mean(max_sim_per_candidate_token_to_category).item()
            else:
                avg_sim_for_current_category = 0.0

            print(f"  Category '{table_name}': Average Max Sim = {avg_sim_for_current_category:.4f}")

            if avg_sim_for_current_category > highest_avg_sim_for_category:
                highest_avg_sim_for_category = avg_sim_for_current_category
                best_category_for_title_semantic = table_name

        print(
            f"  DEBUG: Final best category candidate: '{best_category_for_title_semantic}' with Avg Sim: {highest_avg_sim_for_category:.4f}")
        print(f"  DEBUG: Threshold for addition: {MIN_SIMILARITY_FOR_KEYWORD_ADDITION:.4f}")

        if best_category_for_title_semantic and highest_avg_sim_for_category >= MIN_SIMILARITY_FOR_KEYWORD_ADDITION:
            target_table_name = best_category_for_title_semantic
            print(
                f"  ğŸ¯ Best category for this title: '{target_table_name}' (Overall Avg Max Sim: {highest_avg_sim_for_category:.4f})")

            table_embeddings_for_best_category = current_all_keyword_embeddings[target_table_name]

            keyword_to_add = None
            if table_embeddings_for_best_category.numel() and len(candidate_tokens) > 0:
                final_similarity_matrix_for_best_cat = util.pytorch_cos_sim(candidate_token_embeddings,
                                                                            table_embeddings_for_best_category)
                max_sims_from_title_token_to_best_cat = final_similarity_matrix_for_best_cat.max(dim=1)[0]

                idx_of_best_candidate_token = torch.argmax(max_sims_from_title_token_to_best_cat).item()
                keyword_to_add = candidate_tokens[idx_of_best_candidate_token]

                print(f"  âœ¨ Selected keyword from title to add/update: '{keyword_to_add}'")

                existing_sim_in_target_table = get_keyword_and_similarity_from_table(target_table_name, keyword_to_add)
                print(
                    f"  DEBUG: Existing similarity for '{keyword_to_add}' in '{target_table_name}': {existing_sim_in_target_table}")

                if existing_sim_in_target_table is not None:
                    # í˜„ì¬ í…Œì´ë¸”ì— í‚¤ì›Œë“œê°€ ì´ë¯¸ ì¡´ì¬í•˜ê³ , ìƒˆ í‰ê·  ìœ ì‚¬ë„ê°€ ë” ë†’ë‹¤ë©´
                    if highest_avg_sim_for_category > existing_sim_in_target_table:
                        # ë‹¤ë¥¸ í…Œì´ë¸”ì— ë™ì¼í•œ í‚¤ì›Œë“œê°€ ì—†ëŠ”ì§€ í™•ì¸ í›„ ì—…ë°ì´íŠ¸
                        if not keyword_exists_in_any_other_table(target_table_name, keyword_to_add):
                            print(
                                f"  DEBUG: New average similarity ({highest_avg_sim_for_category:.4f}) > Existing similarity ({existing_sim_in_target_table:.4f}). Attempting update in {target_table_name}.")
                            update_keyword_similarity(target_table_name, keyword_to_add, highest_avg_sim_for_category)
                        else:
                            print(
                                f"  â›” Skipped update for '{keyword_to_add}' in '{target_table_name}'. It already exists in another table.")
                    else:
                        print(
                            f"  ğŸ” Token '{keyword_to_add}' already exists in '{target_table_name}' with higher or equal average similarity ({existing_sim_in_target_table:.4f}). Skipping update.")
                else:
                    # í‚¤ì›Œë“œê°€ í˜„ì¬ í…Œì´ë¸”ì— ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš°
                    # ë‹¤ë¥¸ í…Œì´ë¸”ì— ë™ì¼í•œ í‚¤ì›Œë“œê°€ ì—†ëŠ”ì§€ í™•ì¸ í›„ ì‚½ì…
                    if not keyword_exists_in_any_other_table(target_table_name, keyword_to_add):
                        print(
                            f"  DEBUG: Keyword '{keyword_to_add}' does not exist in '{target_table_name}' and not in other tables. Attempting insertion.")
                        if count_table_entries(target_table_name) >= MAX_KEYWORDS_PER_TABLE:
                            delete_lowest_similarity_keyword(target_table_name)
                        insert_keyword(target_table_name, keyword_to_add, highest_avg_sim_for_category)
                    else:
                        print(
                            f"  â›” Skipped insertion for '{keyword_to_add}' in '{target_table_name}'. It already exists in another table.")
            else:
                print(
                    f"  âš ï¸  No keywords in '{target_table_name}' or no candidate tokens from title to compare with. Cannot determine best candidate keyword for insertion.")
        else:
            print(
                f"  ğŸ¤· No sufficiently relevant category found for this title (Max Avg Sim: {highest_avg_sim_for_category:.4f}, Threshold: {MIN_SIMILARITY_FOR_KEYWORD_ADDITION:.4f}). Skipping keyword learning.")

cursor.close()
conn.close()
print(f"\n--- í‚¤ì›Œë“œ í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ ---")