from flask import Flask, request, jsonify
import mysql.connector
from transformers import BertTokenizer, BertModel
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np


app = Flask(__name__)

# ì‚¬ì „í•™ìŠµëœ KoBERT ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
tokenizer = BertTokenizer.from_pretrained('monologg/kobert')
model = BertModel.from_pretrained('monologg/kobert')

"""
    
"""
# dbì—°ê²°
mydb = mysql.connector.connect(
    host='localhost',
    user='test',
    password='2370',
    database='textdb'
)

"""
    ë³€ìˆ˜ëª… 
    category_keyword(dict/list) -> í‚¤ì›Œë“œì™€ ì„¸ë¶„í™” DBë¡œ ë¶ˆëŸ¬ì˜¤ê¸°.
    sentens -> mailDetail
"""
# ë‚˜ì¤‘ì— dbë¡œ ë°›ì•„ì™€ì•¼ í•¨
# dictionary(key(keyword), list(keywordDetail))ë¡œ ë°›ì•„ì˜¬ ê²ƒ

category_keywords = {
    "ê¸ˆìœµ": [
        "ì¹´ë“œ", "ì‹ ìš©ì¹´ë“œ", "ì²´í¬ì¹´ë“œ", "ê¸ˆìœµ", "ì€í–‰", "ëª…ì„¸ì„œ", "ì‚¬ìš© ë‚´ì—­", "ê±°ëž˜ ë‚´ì—­",
        "ëŒ€ì¶œ", "ëŒ€ì¶œê¸ˆ", "ì´ìž", "ìƒí™˜", "ì—°ì²´", "ê³„ì¢Œ", "ìž”ì•¡", "ì´ì²´", "ì¶œê¸ˆ", "ìž…ê¸ˆ",
        "ìžë™ì´ì²´", "ì²­êµ¬ì„œ", "ë‚©ë¶€", "ìˆ˜ìˆ˜ë£Œ", "ê²°ì œ", "ì¹´ë“œ ìŠ¹ì¸", "ê²°ì œ ì•Œë¦¼",
        "í•œë„ ì´ˆê³¼", "ê³„ì¢Œì´ì²´", "í†µìž¥"
    ],
    "íšŒì‚¬": [
        "íšŒì‚¬", "ì¸ì‚¬íŒ€", "ì¸ì‚¬ ë°œë ¹", "ì¸ì‚¬ ì´ë™", "ì¸ì‚¬ ê³µì§€", "ì¸ì‚¬ í‰ê°€", "ì¸ì‚¬ ê¸°ë¡",
        "ì—…ë¬´", "íšŒì˜", "í”„ë¡œì íŠ¸", "ê³„ì•½ì„œ", "ë°œì£¼", "í´ë ˆìž„", "ê²°ì œìš”ì²­", "ì§€ì¶œ ê²°ì˜ì„œ",
        "ë³´ê³ ì„œ", "ì—…ë¬´ì¼ì§€", "ì „ê²°", "í˜‘ì¡° ìš”ì²­", "ì¶œê·¼", "í‡´ê·¼", "ì•¼ê·¼", "íšŒì˜ë¡", "ê·¼íƒœ",
        "ê¸‰ì—¬", "ì¶œìž¥", "êµìœ¡ ì•ˆë‚´", "ì‚¬ë‚´ ê³µì§€", "ì¡°ì§ë„", "ë¶€ì„œ ì´ë™"
    ],
    "ì •ë¶€": [
        "êµ­ì„¸ì²­", "ì„¸ê¸ˆ", "ì—°ë§ì •ì‚°", "ì†Œë“ í™•ì¸", "í™˜ê¸‰", "ê±´ê°•ë³´í—˜", "êµ­ë¯¼ì—°ê¸ˆ", "ê³ ìš©ë³´í—˜",
        "ì£¼ë¯¼ì„¼í„°", "ì •ë¶€24", "ë¯¼ì›24", "ì¸ì¦ì„œ", "ê³µê³µê¸°ê´€", "ë³´ì¡°ê¸ˆ", "ê³ ì§€ì„œ", "ë‚©ë¶€ê¸°í•œ",
        "ì„¸ë¬´ì„œ", "ì „ìžì„¸ê¸ˆê³„ì‚°ì„œ", "ë‚©ì„¸ìž", "ì†Œë“ê³µì œ", "ì˜ë£Œë¹„", "í–‰ì •ì²˜ë¦¬", "ì§ˆë³‘ì²­",
        "ì „ìž…ì‹ ê³ ", "ì£¼ë¯¼ë“±ë¡", "ë³¸ì¸ ì¸ì¦"
    ],
    "í¬í„¸": [
        "ë¡œê·¸ì¸ ì•Œë¦¼", "ë¡œê·¸ì¸ ì‹œë„", "ë¡œê·¸ì¸ ê¸°ë¡", "ê³„ì • í™œë™", "ê³„ì • ìž ê¹€", "ì´ì¤‘ì¸ì¦",
        "ì¸ì¦ ì½”ë“œ", "OTP", "IP ë³€ê²½", "ë³´ì•ˆ ê²½ê³ ", "ë¹„ë°€ë²ˆí˜¸ ë³€ê²½ ìš”ì²­", "ë¹„ë°€ë²ˆí˜¸ ì´ˆê¸°í™”",
        "ê³„ì • ë„ìš©", "ë¹„ì •ìƒ ì ‘ì†", "ì‚¬ìš©ìž ì¸ì¦", "ì ‘ì† ì•Œë¦¼", "ë¡œê·¸ì¸ ì‹¤íŒ¨", "ë³´ì•ˆ ì„¤ì •",
        "ë¡œê·¸ì¸ ê¸°ê¸°", "ìƒˆë¡œìš´ ê¸°ê¸° ë¡œê·¸ì¸", "ì´ë©”ì¼ ì¸ì¦", "ì¸ì¦ ë©”ì¼", "ë¡œê·¸ì¸ í™•ì¸",
        "ì¸ì¦ ì‹¤íŒ¨", "ì•± ì ‘ê·¼ ì•Œë¦¼", "ì¸ì¦ ë¬¸ìž", "ìžë™ ë¡œê·¸ì•„ì›ƒ"]
}

# ì—°ê²°
if mydb.is_connected():
    print("ë°ì´í„°ë² ì´ìŠ¤ì— ì„±ê³µì ìœ¼ë¡œ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.")
    # ì¿¼ë¦¬ ì‹¤í–‰
    userID = ""

    """
    userID = htmlì—ì„œ ì§ì ‘ ë°›ì•„ì™€ì•¼
    javascriptì—ì„œ ë³´ë‚´ì¤˜ì•¼ ë°›ì•„ì˜¬ ìˆ˜ ìžˆìŒ
    mycursor.execute(f"SELECT mail_detail FROM mail where mail_num = 1  && userID = {userID}")

    """
    mycursor = mydb.cursor()

#     sql = "INSERT INTO mail (mail_num, mail_detail) VALUES (%s, %s)"
#     val = ("9", """â€œâ€â€œï¼‰
    mycursor.execute(f"SELECT mail_detail FROM mail where mail_num = 9 ")

    # ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
    result = mycursor.fetchall()

    # ê²°ê³¼ ì¶œë ¥
    for row in result:
        mail_detail = row[0]
        print(row)

# SBERT ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')

@app.route('/')
def classify_sentence(sentence: str, category_keywords: dict) -> str:
    sentence_vec = model.encode([sentence])  # 2D ë°°ì—´ (1, 768)

    # scores = {}
    # for category, keywords in category_keywords.items():
    #     keyword_vecs = model.encode(keywords)  # shape: (len(keywords), 768)
        #í‰ê· 
    #     sim = cosine_similarity(sentence_vec, keyword_vecs).mean()
    #     scores[category] = sim
    #
    # # ìœ ì‚¬ë„ ì¶œë ¥ ì§€ìš°ê³  best_matchë§Œ ë³´ë‚´ë©´ ë¨
    # for cat, score in scores.items():
    #     print(f"{cat}: {score:.4f}")
    #
    # best_match = max(scores, key=scores.get)
    # return best_match

    all_keywords = []
    keyword_to_category = []

    for category, keywords in category_keywords.items():
        all_keywords.extend(keywords)
        keyword_to_category.extend([category] * len(keywords))

    # ì „ì²´ í‚¤ì›Œë“œ ìž„ë² ë”©
    keyword_vecs = model.encode(all_keywords)  # shape: (N, 768)
    sims = cosine_similarity(sentence_vec, keyword_vecs)[0]  # shape: (N, )

    # ìƒìœ„ 10ê°œ í‚¤ì›Œë“œ ì¸ë±ìŠ¤
    top_k = min(10, len(sims))
    top_indices = np.argsort(sims)[-top_k:][::-1]

    print("\n[Top 10 ìœ ì‚¬ í‚¤ì›Œë“œ]")
    category_score_map = {}

    for i, idx in enumerate(top_indices, 1):
        keyword = all_keywords[idx]
        category = keyword_to_category[idx]
        sim = sims[idx]
        print(f"{i}. ({category}) {keyword} : {sim:.4f}")

        if category not in category_score_map:
            category_score_map[category] = []
        category_score_map[category].append(sim)

    print("\nðŸ“Š [ì¹´í…Œê³ ë¦¬ë³„ í‰ê·  ìœ ì‚¬ë„]")
    avg_scores = {}
    for cat, score_list in category_score_map.items():
        avg = np.mean(score_list)
        avg_scores[cat] = avg
        print(f"- {cat}: í‰ê·  {avg:.4f} ({len(score_list)}ê°œ í‚¤ì›Œë“œ í¬í•¨)")

    best_match = max(avg_scores, key=avg_scores.get)
    return best_match

# í…ŒìŠ¤íŠ¸
# best_match -> DB - mail - keyword
#
sentence = mail_detail
category = classify_sentence(sentence, category_keywords)

print(f"\në¬¸ìž¥ ë¶„ë¥˜ ê²°ê³¼: {category}")

if __name__ == '__main__':
    app.run()