from kiwipiepy import Kiwi
from sentence_transformers import SentenceTransformer, util
import pymysql
import re

# ëª¨ë¸ ë° í˜•íƒœì†Œ ë¶„ì„ê¸° ì´ˆê¸°í™”
model = SentenceTransformer("snunlp/KR-SBERT-V40K-klueNLI-augSTS")
kiwi = Kiwi()

# DB ì—°ê²°
conn = pymysql.connect(
    host='10.50.131.18',
    port=3306,
    user='user',
    password='user1234',
    database='maildb',
    charset='utf8'
)
cursor = conn.cursor()

# í‚¤ì›Œë“œ í…Œì´ë¸” ëª©ë¡
keyword_tables = ['finance_keywords', 'government_keywords', 'portal_keywords', 'advertisement_keywords']

# ëª…ì‚¬/í˜•ìš©ì‚¬ë§Œ ì¶”ì¶œ
def extract_keywords(text):
    tokens = kiwi.tokenize(text)
    return [token.form for token in tokens if token.tag in ("NNG", "NNP", "VA") and token.form.isalpha()]

def get_keywords_from_table(table_name):
    cursor.execute(f"SELECT keywordnum, word, similarity FROM {table_name}")
    return cursor.fetchall()

# í‚¤ì›Œë“œê°€ ì¡´ìž¬í•˜ë©´ í•´ë‹¹ í‚¤ì›Œë“œì˜ í˜„ìž¬ ìœ ì‚¬ë„ë¥¼ ë°˜í™˜í•˜ê³ , ì—†ìœ¼ë©´ Noneì„ ë°˜í™˜
def get_existing_keyword_similarity(table_name, word):
    cursor.execute(f"SELECT similarity FROM {table_name} WHERE word = %s", (word,))
    result = cursor.fetchone()
    return result[0] if result else None

def count_table_entries(table_name):
    cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
    return cursor.fetchone()[0]

def delete_lowest_similarity_keyword(table_name):
    cursor.execute(f"SELECT keywordnum FROM {table_name} ORDER BY similarity ASC LIMIT 1")
    result = cursor.fetchone()
    if result:
        cursor.execute(f"DELETE FROM {table_name} WHERE keywordnum = %s", (result[0],))
        conn.commit()

def insert_keyword(table_name, word, similarity):
    cursor.execute(
        f"INSERT INTO {table_name}(word, similarity) VALUES (%s, %s)",
        (word, similarity)
    )
    conn.commit()

def update_keyword_similarity(table_name, word, new_similarity):
    cursor.execute(
        f"UPDATE {table_name} SET similarity = %s WHERE word = %s",
        (new_similarity, word)
    )
    conn.commit()


# ë©”ì¼ ì œëª© ì „ë¶€ ê°€ì ¸ì˜¤ê¸°
cursor.execute("SELECT title FROM mail_info")
titles = [row[0] for row in cursor.fetchall()]

# ì „ì²´ ì²˜ë¦¬
for title in titles:
    print(f"\nðŸ“¨ Processing title: {title}")
    tokens = extract_keywords(title)
    if not tokens:
        print("â›” No valid tokens found.")
        continue

    token_embeddings = model.encode(tokens, convert_to_tensor=True)

    for table in keyword_tables:
        keyword_rows = get_keywords_from_table(table)
        # í…Œì´ë¸”ì´ ë¹„ì–´ìžˆëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•˜ì—¬ ë¹„ì–´ìžˆì§€ ì•Šë„ë¡ ì²˜ë¦¬
        if not keyword_rows:
            print(f"âš ï¸  Table {table} is empty. No keywords to compare against. Skipping this table for now.")
            continue  # ë‹¤ìŒ í…Œì´ë¸”ë¡œ ë„˜ì–´ê°

        max_similarity = 0.0
        best_token = None

        # í˜„ìž¬ í…Œì´ë¸”ì˜ í‚¤ì›Œë“œ ìž„ë² ë”©ì„ ë¯¸ë¦¬ ê³„ì‚°
        table_words = [row[1] for row in keyword_rows]
        if not table_words:  # í…Œì´ë¸”ì— ë‹¨ì–´ê°€ ì—†ëŠ” ê²½ìš° ë‹¤ì‹œ í™•ì¸
            continue  # ë‹¤ìŒ í…Œì´ë¸”ë¡œ ë„˜ì–´ê°

        table_word_embeddings = model.encode(table_words, convert_to_tensor=True)

        for i, token in enumerate(tokens):
            token_embedding = token_embeddings[i]
            # ì¶”ì¶œëœ í† í°ê³¼ í…Œì´ë¸” ë‚´ ëª¨ë“  í‚¤ì›Œë“œ ê°„ì˜ ìœ ì‚¬ë„ ê³„ì‚°
            similarities = util.pytorch_cos_sim(token_embedding, table_word_embeddings)

            # í˜„ìž¬ í† í°ì— ëŒ€í•œ í…Œì´ë¸” ë‚´ ìµœëŒ€ ìœ ì‚¬ë„ ì°¾ê¸°
            current_max_similarity = similarities.max().item()  # .item()ìœ¼ë¡œ í…ì„œ ê°’ì„ Python ìˆ«ìžë¡œ ë³€í™˜

            if current_max_similarity > max_similarity:
                max_similarity = current_max_similarity
                best_token = token

        if best_token:
            existing_similarity = get_existing_keyword_similarity(table, best_token)

            if max_similarity <= 0.5:
                print(f"ðŸ§Š Token '{best_token}' skipped for {table} (similarity {max_similarity:.2f} too low).")
            elif existing_similarity is not None:  # í‚¤ì›Œë“œê°€ ì´ë¯¸ ì¡´ìž¬í•œë‹¤ë©´
                if max_similarity > existing_similarity:
                    update_keyword_similarity(table, best_token, max_similarity)
                    print(
                        f"ðŸ”„ Updated '{best_token}' in {table} with higher similarity: {max_similarity:.2f} (was: {existing_similarity:.2f})")
                else:
                    print(
                        f"ðŸ” Token '{best_token}' already exists in {table} with higher or equal similarity ({existing_similarity:.2f}). Skipping update.")
            else:  # í‚¤ì›Œë“œê°€ ì¡´ìž¬í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´ ìƒˆë¡œ ì‚½ìž…
                if count_table_entries(table) >= 300:
                    delete_lowest_similarity_keyword(table)
                    print(f"ðŸ—‘ Deleted lowest similarity keyword from {table} to make room.")
                insert_keyword(table, best_token, max_similarity)
                print(f"âœ… Inserted '{best_token}' into {table} (similarity: {max_similarity:.2f})")

# ì—°ê²° ì¢…ë£Œ
cursor.close()
conn.close()