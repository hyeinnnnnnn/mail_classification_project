from kiwipiepy import Kiwi
from sentence_transformers import SentenceTransformer, util
import pymysql
import re
import torch

# ëª¨ë¸ ë° í˜•íƒœì†Œ ë¶„ì„ê¸° ì´ˆê¸°í™”
model = SentenceTransformer("snunlp/KR-SBERT-V40K-klueNLI-augSTS")
kiwi = Kiwi()

# DB ì—°ê²°
conn = pymysql.connect(
    host='10.50.131.18',
    port=3306,
    user='user',
    password='user1234',
    database='maildb',
    charset='utf8'
)
cursor = conn.cursor()

# í‚¤ì›Œë“œ í…Œì´ë¸” ëª©ë¡
keyword_tables = ['finance_keywords', 'government_keywords', 'portal_keywords', 'advertisement_keywords']


# ëª…ì‚¬/í˜•ìš©ì‚¬ë§Œ ì¶”ì¶œ
def extract_keywords(text):
    tokens = kiwi.tokenize(text)
    # isalpha()ë¥¼ ì¶”ê°€í•˜ì—¬ ìˆ«ìë‚˜ íŠ¹ìˆ˜ë¬¸ìê°€ í¬í•¨ëœ í† í°ì€ ì œì™¸
    return [token.form for token in tokens if token.tag in ("NNG", "NNP", "VA") and token.form.isalpha()]


def get_keywords_from_table(table_name):
    cursor.execute(f"SELECT keywordnum, word, similarity FROM {table_name}")
    return cursor.fetchall()


def get_existing_keyword_similarity(table_name, word):
    cursor.execute(f"SELECT similarity FROM {table_name} WHERE word = %s", (word,))
    result = cursor.fetchone()
    return result[0] if result else None


def keyword_exists(table_name, word):
    cursor.execute(f"SELECT 1 FROM {table_name} WHERE word = %s", (word,))
    return cursor.fetchone() is not None


def count_table_entries(table_name):
    cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
    return cursor.fetchone()[0]


def delete_lowest_similarity_keyword(table_name):
    cursor.execute(f"SELECT keywordnum FROM {table_name} ORDER BY similarity ASC LIMIT 1")
    result = cursor.fetchone()
    if result:
        cursor.execute(f"DELETE FROM {table_name} WHERE keywordnum = %s", (result[0],))
        conn.commit()


def insert_keyword(table_name, word, similarity):
    cursor.execute(
        f"INSERT INTO {table_name}(word, similarity) VALUES (%s, %s)",
        (word, similarity)
    )
    conn.commit()


def update_keyword_similarity(table_name, word, new_similarity):
    cursor.execute(
        f"UPDATE {table_name} SET similarity = %s WHERE word = %s",
        (new_similarity, word)
    )
    conn.commit()


# ëª¨ë“  í‚¤ì›Œë“œ í…Œì´ë¸”ì—ì„œ íŠ¹ì • ë‹¨ì–´ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸ (í˜„ì¬ í…Œì´ë¸” ì œì™¸)
def keyword_exists_in_any_other_table(current_table_name, word):
    for table_name in keyword_tables:
        if table_name == current_table_name:
            continue
        cursor.execute(f"SELECT 1 FROM {table_name} WHERE word = %s", (word,))
        if cursor.fetchone() is not None:
            return True
    return False


# ë©”ì¼ ë‚´ìš© ì „ë¶€ ê°€ì ¸ì˜¤ê¸°
cursor.execute("SELECT detail FROM mail_info")
details = [row[0] for row in cursor.fetchall()]

# ì¿¼ë¦¬ ì¹´ìš´íŠ¸ ì´ˆê¸°í™”
query_count = 0

# --- ë©”ì¸ ì²˜ë¦¬ ë£¨í”„ ---
for detail in details:
    query_count += 1
    # ë©”ì¼ ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ì„œ ì¶œë ¥
    display_detail = detail if len(detail) < 100 else detail[:97] + "..."
    print(f"\n--- Processing Mail {query_count} ---")
    print(f"  Content: '{display_detail}'")

    tokens = extract_keywords(detail)
    if not tokens:
        print("  â›” No valid tokens (nouns/adjectives) found for this content.")
        continue

    detail_token_embeddings = model.encode(tokens, convert_to_tensor=True)

    best_table_for_detail = None
    max_avg_similarity_for_detail = -1.0  # ë©”ì¼ ë‚´ìš©ê³¼ í…Œì´ë¸” ê°„ì˜ ìµœê³  í‰ê·  ìœ ì‚¬ë„
    best_token_for_table_insertion = None  # ì‹¤ì œë¡œ ì‚½ì…/ì—…ë°ì´íŠ¸ë  í‚¤ì›Œë“œ (í•´ë‹¹ í…Œì´ë¸”ê³¼ì˜ ê°œë³„ ìœ ì‚¬ë„ ê¸°ì¤€)

    # ê° í‚¤ì›Œë“œ í…Œì´ë¸”ë³„ í‰ê·  ìœ ì‚¬ë„ ê³„ì‚° ë° ìµœì  í…Œì´ë¸” ì„ íƒ
    for table_name in keyword_tables:
        keyword_rows = get_keywords_from_table(table_name)
        if not keyword_rows:
            # print(f"âš ï¸  Table {table_name} is empty. Skipping average similarity calculation for this table.")
            continue

        table_words = [row[1] for row in keyword_rows]
        table_word_embeddings = model.encode(table_words, convert_to_tensor=True)

        similarity_matrix = util.pytorch_cos_sim(detail_token_embeddings, table_word_embeddings)
        max_similarities_per_detail_token = similarity_matrix.max(dim=1)[0]

        if len(max_similarities_per_detail_token) > 0:
            avg_similarity_for_table = torch.mean(max_similarities_per_detail_token).item()
        else:
            avg_similarity_for_table = 0.0

        # í˜„ì¬ í…Œì´ë¸”ì´ ì§€ê¸ˆê¹Œì§€ ì°¾ì€ ìµœê³  í‰ê·  ìœ ì‚¬ë„ë¥¼ ê°€ì§„ í…Œì´ë¸”ì´ë¼ë©´ ì—…ë°ì´íŠ¸
        if avg_similarity_for_table > max_avg_similarity_for_detail:
            max_avg_similarity_for_detail = avg_similarity_for_table
            best_table_for_detail = table_name

            # ì´ í…Œì´ë¸”ì— ì‚½ì…ë  ê°€ì¥ ì í•©í•œ ë‹¨ì¼ í‚¤ì›Œë“œë¥¼ ì°¾ìŠµë‹ˆë‹¤.
            # ì´ëŠ” ë©”ì¼ ë‚´ìš©ì˜ í† í° ì¤‘, í•´ë‹¹ í…Œì´ë¸”ì˜ í‚¤ì›Œë“œë“¤ê³¼ ê°€ì¥ ë†’ì€ ìœ ì‚¬ë„ë¥¼ ë³´ì´ëŠ” í† í°ì…ë‹ˆë‹¤.
            if len(max_similarities_per_detail_token) > 0:
                idx_of_best_token_in_detail = torch.argmax(max_similarities_per_detail_token).item()
                best_token_for_table_insertion = tokens[idx_of_best_token_in_detail]
            else:
                best_token_for_table_insertion = None

    # ìµœì†Œ í‰ê·  ìœ ì‚¬ë„ ì„ê³„ì¹˜ (ì´ ê°’ì„ ì¡°ì ˆí•˜ì—¬ ë¯¼ê°ë„ë¥¼ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.)
    MIN_AVG_SIMILARITY_THRESHOLD = 0.35

    # ìµœì¢… ì„ íƒëœ í…Œì´ë¸”ì— í‚¤ì›Œë“œ ë°˜ì˜ (ì‚½ì… ë˜ëŠ” ì—…ë°ì´íŠ¸)
    if best_table_for_detail and best_token_for_table_insertion and max_avg_similarity_for_detail >= MIN_AVG_SIMILARITY_THRESHOLD:
        target_table = best_table_for_detail
        best_token = best_token_for_table_insertion
        similarity_to_save = max_avg_similarity_for_detail  # DBì— ì €ì¥ë  ìœ ì‚¬ë„ ê°’ì€ í…Œì´ë¸”ì˜ í‰ê·  ìœ ì‚¬ë„

        # í‚¤ì›Œë“œê°€ ì´ë¯¸ íƒ€ê²Ÿ í…Œì´ë¸”ì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if keyword_exists(target_table, best_token):
            existing_similarity = get_existing_keyword_similarity(target_table, best_token)

            if similarity_to_save > existing_similarity:  # ìƒˆ í‰ê·  ìœ ì‚¬ë„ê°€ ê¸°ì¡´ ìœ ì‚¬ë„ë³´ë‹¤ ë†’ë‹¤ë©´ ì—…ë°ì´íŠ¸
                # ë‹¤ë¥¸ í…Œì´ë¸”ì— ë™ì¼í•œ í‚¤ì›Œë“œê°€ ì—†ëŠ”ì§€ í™•ì¸ í›„ ì—…ë°ì´íŠ¸ (ì¤‘ë³µ ë°©ì§€)
                if not keyword_exists_in_any_other_table(target_table, best_token):
                    update_keyword_similarity(target_table, best_token, similarity_to_save)
                    print(
                        f"  âœ… Updated keyword: '{best_token}' in {target_table} (New Avg Sim: {similarity_to_save:.2f}, Prev: {existing_similarity:.2f})")
                else:
                    print(
                        f"  â›” Skipped update for '{best_token}' in {target_table}. It already exists in another table.")
            else:
                print(
                    f"  â†”ï¸ Keyword: '{best_token}' in {target_table} (Avg Sim: {existing_similarity:.2f}). No higher average similarity found.")
        else:  # í‚¤ì›Œë“œê°€ í˜„ì¬ í…Œì´ë¸”ì— ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´ ìƒˆë¡œ ì‚½ì…
            # ë‹¤ë¥¸ í…Œì´ë¸”ì— ë™ì¼í•œ í‚¤ì›Œë“œê°€ ì—†ëŠ”ì§€ í™•ì¸ í›„ ì‚½ì… (ì¤‘ë³µ ë°©ì§€)
            if not keyword_exists_in_any_other_table(target_table, best_token):
                if count_table_entries(target_table) >= 300:  # í…Œì´ë¸” ìš©ëŸ‰ ì´ˆê³¼ ì‹œ ê°€ì¥ ë‚®ì€ ìœ ì‚¬ë„ í‚¤ì›Œë“œ ì‚­ì œ
                    delete_lowest_similarity_keyword(target_table)
                    print(f"  ğŸ—‘ Deleted lowest similarity keyword from {target_table} to make room.")
                insert_keyword(target_table, best_token, similarity_to_save)
                print(f"  â• Inserted keyword: '{best_token}' into {target_table} (Avg Sim: {similarity_to_save:.2f})")
            else:
                print(
                    f"  â›” Skipped insertion for '{best_token}' in {target_table}. It already exists in another table.")
    else:
        # ì´ ì¤„ì—ì„œ ë³€ìˆ˜ëª…ì„ max_avg_similarity_for_detailë¡œ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.
        print(
            f"  ğŸ¤· No sufficiently relevant table found for this content (Max Avg Sim: {max_avg_similarity_for_detail:.2f}, Threshold: {MIN_AVG_SIMILARITY_THRESHOLD}).")

# --- DB ì—°ê²° ì¢…ë£Œ ---
cursor.close()
conn.close()