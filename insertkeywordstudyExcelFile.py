import sys
from kiwipiepy import Kiwi
from sentence_transformers import SentenceTransformer, util
import pymysql
import re
import torch
import pandas as pd  # pandas ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸

# openpyxlì´ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šë‹¤ë©´, í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”:
# pip install openpyxl

# ëª¨ë¸ ë° í˜•íƒœì†Œ ë¶„ì„ê¸° ì´ˆê¸°í™”
model = SentenceTransformer("snunlp/KR-SBERT-V40K-klueNLI-augSTS")
kiwi = Kiwi()

# DB ì—°ê²° (í‚¤ì›Œë“œ í…Œì´ë¸” ì‚½ì…/ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•´ í•„ìš”)
try:
    conn = pymysql.connect(
        host='10.50.131.18',
        port=3306,
        user='user',
        password='user1234',
        database='maildb',  # í‚¤ì›Œë“œ í…Œì´ë¸”ì´ ìˆëŠ” ë°ì´í„°ë² ì´ìŠ¤
        charset='utf8'
    )
    cursor = conn.cursor()

except pymysql.Error as e:
    print(f"DB ì—°ê²° ì˜¤ë¥˜: {e}")
    sys.exit(1)

# í‚¤ì›Œë“œ í…Œì´ë¸” ëª©ë¡ (ì¹´í…Œê³ ë¦¬ ëª©ë¡)
keyword_tables = ['finance_keywords', 'government_keywords', 'portal_keywords', 'advertisement_keywords']


# ëª…ì‚¬/í˜•ìš©ì‚¬ë§Œ ì¶”ì¶œ (NNG: ì¼ë°˜ ëª…ì‚¬, NNP: ê³ ìœ  ëª…ì‚¬, VA: í˜•ìš©ì‚¬)
def extract_nouns_and_adjectives(text):
    tokens = kiwi.tokenize(text)
    return [token.form for token in tokens if token.tag in ("NNG", "NNP", "VA") and token.form.isalpha()]


def get_keywords_from_table(table_name):
    cursor.execute(f"SELECT word FROM {table_name}")
    return [row[0] for row in cursor.fetchall()]


def get_keyword_and_similarity_from_table(table_name, word):
    cursor.execute(f"SELECT similarity FROM {table_name} WHERE word = %s", (word,))
    result = cursor.fetchone()
    return result[0] if result else None


def count_table_entries(table_name):
    cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
    return cursor.fetchone()[0]


def delete_lowest_similarity_keyword(table_name):
    cursor.execute(f"SELECT keywordnum FROM {table_name} ORDER BY similarity ASC LIMIT 1")
    result = cursor.fetchone()
    if result:
        cursor.execute(f"DELETE FROM {table_name} WHERE keywordnum = %s", (result[0],))
        conn.commit()
        print(f"ğŸ—‘ Deleted lowest similarity keyword from {table_name} to make room.")
        return True
    return False


def insert_keyword(table_name, word, similarity):
    try:
        cursor.execute(
            f"INSERT INTO {table_name}(word, similarity) VALUES (%s, %s)",
            (word, similarity)
        )
        conn.commit()
        print(f"âœ… Inserted '{word}' into {table_name} (similarity: {similarity:.4f})")
        return True
    except pymysql.Error as e:
        print(f"DB ì‚½ì… ì˜¤ë¥˜ ({table_name}, {word}): {e}")
        conn.rollback()
        return False


def update_keyword_similarity(table_name, word, new_similarity):
    try:
        cursor.execute(
            f"UPDATE {table_name} SET similarity = %s WHERE word = %s",
            (new_similarity, word)
        )
        conn.commit()
        print(f"ğŸ”„ Updated '{word}' in {table_name} with new similarity: {new_similarity:.4f}")
        return True
    except pymysql.Error as e:
        print(f"DB ì—…ë°ì´íŠ¸ ì˜¤ë¥˜ ({table_name}, {word}): {e}")
        conn.rollback()
        return False


# í˜„ì¬ í…Œì´ë¸”ì„ ì œì™¸í•œ ë‹¤ë¥¸ í…Œì´ë¸”ì—ì„œ í‚¤ì›Œë“œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
def keyword_exists_in_any_other_table(current_table_name, word):
    for table_name in keyword_tables:
        if table_name == current_table_name:  # í˜„ì¬ í…Œì´ë¸”ì€ ê±´ë„ˆëœ€
            continue
        cursor.execute(f"SELECT 1 FROM {table_name} WHERE word = %s", (word,))
        if cursor.fetchone() is not None:
            return True  # ë‹¤ë¥¸ í…Œì´ë¸”ì—ì„œ ë°œê²¬ë¨
    return False  # ë‹¤ë¥¸ í…Œì´ë¸”ì—ì„œëŠ” ë°œê²¬ë˜ì§€ ì•ŠìŒ


if __name__ == "__main__":
    # --- XLSX íŒŒì¼ì—ì„œ ë©”ì¼ ì œëª© ì½ì–´ì˜¤ê¸° ---
    # ì—¬ê¸°ì— XLSX íŒŒì¼ ê²½ë¡œë¥¼ ì§€ì •í•˜ì„¸ìš”.
    # ì˜ˆ: "C:/Users/YourUser/Documents/government_mail_samples_1000.xlsx"
    xlsx_file_path = "goverment_title_detail.xlsx"
    titles_to_process = []
    try:
        # pd.read_excel()ì„ ì‚¬ìš©í•˜ì—¬ XLSX íŒŒì¼ ì½ê¸°
        df_mails = pd.read_excel(xlsx_file_path)
        if 'title' in df_mails.columns:
            # ì œëª© ì»¬ëŸ¼ì˜ ë°ì´í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            titles_to_process = df_mails['title'].tolist()
            print(f"âœ”ï¸ '{xlsx_file_path}'ì—ì„œ {len(titles_to_process)}ê°œì˜ ë©”ì¼ ì œëª©ì„ ì„±ê³µì ìœ¼ë¡œ ì½ì–´ì™”ìŠµë‹ˆë‹¤.")
        else:
            print(f"â›” ì˜¤ë¥˜: '{xlsx_file_path}' íŒŒì¼ì— 'title' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ì»¬ëŸ¼ ì´ë¦„ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            conn.close()
            sys.exit(1)
    except FileNotFoundError:
        print(f"â›” ì˜¤ë¥˜: '{xlsx_file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        print(f"   í˜¹ì‹œ 'openpyxl' ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ë‹¤ë©´, 'pip install openpyxl'ì„ ì‹¤í–‰í•´ë³´ì„¸ìš”.")
        conn.close()
        sys.exit(1)
    except Exception as e:
        print(f"â›” XLSX íŒŒì¼ ì½ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(f"   í˜¹ì‹œ 'openpyxl' ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ë‹¤ë©´, 'pip install openpyxl'ì„ ì‹¤í–‰í•´ë³´ì„¸ìš”.")
        conn.close()
        sys.exit(1)
    # ------------------------------------

    if not titles_to_process:
        print("ì²˜ë¦¬í•  ë©”ì¼ ì œëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
        conn.close()
        sys.exit(0)

    MAX_KEYWORDS_PER_TABLE = 300
    MIN_SIMILARITY_FOR_KEYWORD_ADDITION = 0.45

    for mail_idx, title in enumerate(titles_to_process):
        print(f"\n--- {mail_idx + 1}/{len(titles_to_process)} Processing Mail Title for Keyword Learning ---")
        # titleì´ NaN(Not a Number)ì¼ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì²˜ë¦¬
        display_title = str(title) if len(str(title)) < 70 else str(title)[:67] + "..."
        print(f"  Mail Title: '{display_title}'")

        # pandasê°€ ì½ì€ ë°ì´í„° ì¤‘ NaN ê°’ì´ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë¬¸ìì—´ íƒ€ì…ì¸ì§€ í™•ì¸
        if not isinstance(title, str):
            print(f"â›” Skipping non-string or NaN title: {title}")
            continue

        candidate_tokens = extract_nouns_and_adjectives(title)
        print(f"  DEBUG: Extracted candidate tokens: {candidate_tokens}")
        if not candidate_tokens:
            print(
                "â›” No valid noun/adjective tokens found in this mail title. Skipping keyword learning for this title.")
            continue

        candidate_token_embeddings = model.encode(candidate_tokens, convert_to_tensor=True)

        current_all_table_keywords = {}
        current_all_keyword_embeddings = {}

        for table_name in keyword_tables:
            keywords_in_table = get_keywords_from_table(table_name)
            current_all_table_keywords[table_name] = keywords_in_table
            if keywords_in_table:
                current_all_keyword_embeddings[table_name] = model.encode(keywords_in_table, convert_to_tensor=True)
            else:
                current_all_keyword_embeddings[table_name] = torch.tensor([])

        best_category_for_title_semantic = None
        highest_avg_sim_for_category = -1.0

        for table_name in keyword_tables:
            embeddings_in_table = current_all_keyword_embeddings[table_name]

            if not embeddings_in_table.numel():
                print(f"  âš ï¸  Category '{table_name}' has no embeddings. Skipping similarity calculation.")
                continue

            similarity_matrix = util.pytorch_cos_sim(candidate_token_embeddings, embeddings_in_table)
            max_sim_per_candidate_token_to_category = similarity_matrix.max(dim=1)[0]

            if len(max_sim_per_candidate_token_to_category) > 0:
                avg_sim_for_current_category = torch.mean(max_sim_per_candidate_token_to_category).item()
            else:
                avg_sim_for_current_category = 0.0

            print(f"  Category '{table_name}': Average Max Sim = {avg_sim_for_current_category:.4f}")

            if avg_sim_for_current_category > highest_avg_sim_for_category:
                highest_avg_sim_for_category = avg_sim_for_current_category
                best_category_for_title_semantic = table_name

        print(
            f"  DEBUG: Final best category candidate: '{best_category_for_title_semantic}' with Avg Sim: {highest_avg_sim_for_category:.4f}")
        print(f"  DEBUG: Threshold for addition: {MIN_SIMILARITY_FOR_KEYWORD_ADDITION:.4f}")

        if best_category_for_title_semantic and highest_avg_sim_for_category >= MIN_SIMILARITY_FOR_KEYWORD_ADDITION:
            target_table_name = best_category_for_title_semantic
            print(
                f"  ğŸ¯ Best category for this title: '{target_table_name}' (Overall Avg Max Sim: {highest_avg_sim_for_category:.4f})")

            table_embeddings_for_best_category = current_all_keyword_embeddings[target_table_name]

            keyword_to_add = None
            if table_embeddings_for_best_category.numel() and len(candidate_tokens) > 0:
                final_similarity_matrix_for_best_cat = util.pytorch_cos_sim(candidate_token_embeddings,
                                                                            table_embeddings_for_best_category)
                max_sims_from_title_token_to_best_cat = final_similarity_matrix_for_best_cat.max(dim=1)[0]

                # Check if max_sims_from_title_token_to_best_cat is empty
                if max_sims_from_title_token_to_best_cat.numel() > 0:
                    idx_of_best_candidate_token = torch.argmax(max_sims_from_title_token_to_best_cat).item()
                    keyword_to_add = candidate_tokens[idx_of_best_candidate_token]
                else:
                    print(
                        f"  âš ï¸  No maximum similarity found for candidate tokens in '{target_table_name}'. Skipping keyword selection.")
                    continue

                print(f"  âœ¨ Selected keyword from title to add/update: '{keyword_to_add}'")

                existing_sim_in_target_table = get_keyword_and_similarity_from_table(target_table_name, keyword_to_add)
                print(
                    f"  DEBUG: Existing similarity for '{keyword_to_add}' in '{target_table_name}': {existing_sim_in_target_table}")

                if existing_sim_in_target_table is not None:
                    if highest_avg_sim_for_category > existing_sim_in_target_table:
                        print(
                            f"  DEBUG: New average similarity ({highest_avg_sim_for_category:.4f}) > Existing similarity ({existing_sim_in_target_table:.4f}). Attempting update in {target_table_name}.")
                        if not keyword_exists_in_any_other_table(target_table_name, keyword_to_add):
                            update_keyword_similarity(target_table_name, keyword_to_add, highest_avg_sim_for_category)
                        else:
                            print(
                                f"  â›” Skipped update for '{keyword_to_add}' in '{target_table_name}'. It already exists in another table.")
                    else:
                        print(
                            f"  ğŸ” Token '{keyword_to_add}' already exists in '{target_table_name}' with higher or equal average similarity ({existing_sim_in_target_table:.4f}). Skipping update.")
                else:
                    print(
                        f"  DEBUG: Keyword '{keyword_to_add}' does not exist in '{target_table_name}'. Attempting insertion.")
                    if not keyword_exists_in_any_other_table(target_table_name, keyword_to_add):
                        if count_table_entries(target_table_name) >= MAX_KEYWORDS_PER_TABLE:
                            delete_lowest_similarity_keyword(target_table_name)
                        insert_keyword(target_table_name, keyword_to_add, highest_avg_sim_for_category)
                    else:
                        print(
                            f"  â›” Skipped insertion for '{keyword_to_add}' in '{target_table_name}'. It already exists in another table.")
            else:
                print(
                    f"  âš ï¸  No keywords in '{target_table_name}' or no candidate tokens from title to compare with. Cannot determine best candidate keyword for insertion.")
        else:
            print(
                f"  ğŸ¤· No sufficiently relevant category found for this title (Max Avg Sim: {highest_avg_sim_for_category:.4f}, Threshold: {MIN_SIMILARITY_FOR_KEYWORD_ADDITION:.4f}). Skipping keyword learning.")

cursor.close()
conn.close()
print(f"\n--- í‚¤ì›Œë“œ í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ ---")